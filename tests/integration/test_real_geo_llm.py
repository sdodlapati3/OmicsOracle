#!/usr/bin/env python3
"""
Real GEO Data Test for LLM Integration

This script tests the LLM summarization feature with actual GEO queries.
"""

import asyncio
import sys
from pathlib import Path

# Add the src directory to the Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from omics_oracle.pipeline.pipeline import OmicsOracle, ResultFormat


async def test_real_geo_query():
    """Test with a real GEO query."""
    print("ğŸ”¬ Testing LLM Integration with Real GEO Data")
    print("=" * 50)

    # Initialize the pipeline
    oracle = OmicsOracle()

    try:
        # Test query
        query = "diabetes pancreatic beta cells"
        print(f"ğŸ” Query: '{query}'")
        print("ğŸ“¡ Searching GEO database...")

        # Process the query
        result = await oracle.process_query(
            query, max_results=3, result_format=ResultFormat.JSON
        )

        print(f"\nğŸ“Š Query Status: {result.status.value}")
        print(
            f"â±ï¸  Processing Time: {result.duration:.2f}s"
            if result.duration
            else "â±ï¸  Processing Time: N/A"
        )

        if result.is_failed:
            print(f"âŒ Query failed: {result.error}")
            return False

        print(f"ğŸ“ˆ Found {len(result.geo_ids)} GEO IDs")
        print(f"ğŸ“š Retrieved {len(result.metadata)} datasets with metadata")

        # Display GEO IDs found
        if result.geo_ids:
            print("\nğŸ†” GEO IDs Found:")
            for i, geo_id in enumerate(result.geo_ids[:5], 1):
                print(f"   {i}. {geo_id}")

        # Display AI summaries if available
        if result.ai_summaries:
            print("\nğŸ¤– AI-Generated Summaries:")
            print("-" * 40)

            # Batch summary
            if "batch_summary" in result.ai_summaries:
                batch = result.ai_summaries["batch_summary"]
                print("ğŸ“‹ Batch Overview:")
                print(f"   Total datasets: {batch.get('total_datasets', 0)}")
                print(f"   Total samples: {batch.get('total_samples', 0)}")
                print(f"   Organisms: {', '.join(batch.get('organisms', []))}")
                print(f"   Overview: {batch.get('overview', 'N/A')}")
                print()

            # Brief overview
            if "brief_overview" in result.ai_summaries:
                brief = result.ai_summaries["brief_overview"]
                print("ğŸ¯ Brief Overview:")
                if isinstance(brief, dict):
                    for key, value in brief.items():
                        if value:
                            print(f"   {key}: {value}")
                else:
                    print(f"   {brief}")
                print()

            # Individual summaries
            if "individual_summaries" in result.ai_summaries:
                print("ğŸ“š Top Dataset Summaries:")
                for i, summary_data in enumerate(
                    result.ai_summaries["individual_summaries"][:2], 1
                ):
                    print(
                        f"\n   ğŸ”¬ Dataset {i}: {summary_data.get('accession', 'Unknown')}"
                    )
                    dataset_summaries = summary_data.get("summary", {})

                    if "overview" in dataset_summaries:
                        print(
                            f"      Overview: {dataset_summaries['overview'][:200]}..."
                        )

                    if "technical_details" in dataset_summaries:
                        print(
                            f"      Technical: {dataset_summaries['technical_details']}"
                        )
        else:
            print("\nâš ï¸  No AI summaries generated")

        # Display some metadata if available
        if result.metadata:
            print("\nğŸ“„ Sample Metadata (first dataset):")
            first = result.metadata[0]
            print(f"   Accession: {first.get('accession', 'N/A')}")
            print(f"   Title: {first.get('title', 'N/A')[:100]}...")
            print(f"   Organism: {first.get('organism', 'N/A')}")
            print(f"   Platform: {first.get('platform', 'N/A')}")
            print(f"   Relevance Score: {first.get('relevance_score', 0)}")

        return True

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback

        traceback.print_exc()
        return False

    finally:
        await oracle.close()


async def main():
    """Run the test."""
    success = await test_real_geo_query()

    if success:
        print("\nâœ… Real GEO data integration test completed successfully!")
        print("\nğŸ’¡ The LLM integration is working with live GEO data!")
        print("ğŸ’¡ You can now use this feature in the web interface or CLI.")
    else:
        print("\nâŒ Test failed. Check the error messages above.")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
